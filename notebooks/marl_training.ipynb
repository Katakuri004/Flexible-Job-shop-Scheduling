{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARL Training Demo â€“ Actor-Critic on FJSP\n",
    "\n",
    "This notebook runs a short training session of the simple actor-critic policy on the toy Brandimarte-style FJSP instance and visualizes learning curves and policy behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.seed_utils import SeedConfig, set_global_seeds\n",
    "from src.ac_training import TrainingConfig, run_training\n",
    "\n",
    "# Global seed for notebook reproducibility\n",
    "set_global_seeds(SeedConfig(base_seed=2026))\n",
    "\n",
    "instance_path = Path(\"data/brandimarte_mk_toy.txt\")\n",
    "\n",
    "train_config = TrainingConfig(\n",
    "    instance_path=instance_path,\n",
    "    seed_config=SeedConfig(base_seed=2026),\n",
    "    num_episodes=100,\n",
    "    max_steps_per_episode=64,\n",
    "    log_interval=20,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick smoke test: run a single episode with the untrained policy via run_training on a tiny run\n",
    "small_config = TrainingConfig(\n",
    "    instance_path=instance_path,\n",
    "    seed_config=SeedConfig(base_seed=2027),\n",
    "    num_episodes=5,\n",
    "    max_steps_per_episode=32,\n",
    "    log_interval=5,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "small_metrics = run_training(small_config)\n",
    "small_metrics[\"episode_rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training run (short)\n",
    "metrics = run_training(train_config)\n",
    "\n",
    "episode_rewards = np.array(metrics[\"episode_rewards\"])  # negative makespan sums\n",
    "episode_makespans = np.array(metrics[\"episode_makespans\"])\n",
    "losses = np.array(metrics[\"losses\"])\n",
    "value_losses = np.array(metrics[\"value_losses\"])\n",
    "\n",
    "episode_rewards[:5], episode_makespans[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "episodes = np.arange(1, len(episode_rewards) + 1)\n",
    "\n",
    "axes[0].plot(episodes, episode_rewards, label=\"Episode reward (sum of step rewards)\")\n",
    "axes[0].set_ylabel(\"Reward\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(episodes, episode_makespans, label=\"Final makespan\", color=\"tab:orange\")\n",
    "axes[1].set_ylabel(\"Makespan\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(episodes, losses, label=\"Total loss\")\n",
    "axes[2].plot(episodes, value_losses, label=\"Value loss\", linestyle=\"--\")\n",
    "axes[2].set_xlabel(\"Episode\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "axes[2].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy behaviour visualisation\n",
    "\n",
    "Load the last checkpoint and run a few evaluation episodes with a deterministic policy to visualise schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.fjsp_env import FJSPEnv, FJSPEnvConfig\n",
    "from src.graph_builder import build_graph_from_env_state\n",
    "from src.marl_policy import FJSPActorCritic\n",
    "\n",
    "# Load last checkpoint from training run above\n",
    "ckpt_path = train_config.checkpoint_dir / f\"{train_config.checkpoint_prefix}_ep{train_config.num_episodes}.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "policy_eval = FJSPActorCritic()\n",
    "policy_eval.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "policy_eval.eval()\n",
    "\n",
    "env_cfg = FJSPEnvConfig(instance_path=instance_path, seed_config=SeedConfig(base_seed=3030))\n",
    "env = FJSPEnv(env_cfg)\n",
    "\n",
    "def run_eval_episode(env: FJSPEnv, policy: FJSPActorCritic):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    trajectory = []\n",
    "\n",
    "    while not done and step < 64:\n",
    "        assert env._step_jobs is not None\n",
    "        assert env._step_machines is not None\n",
    "\n",
    "        graph = build_graph_from_env_state(env._step_jobs, env._step_machines)\n",
    "        feasible_actions = obs[\"feasible_actions\"]\n",
    "\n",
    "        out = policy.get_action_and_value(graph, feasible_actions, deterministic=True)\n",
    "        action_idx, logits, value = out\n",
    "\n",
    "        obs, reward, done, info = env.step(action_idx)\n",
    "        trajectory.append((step, feasible_actions, action_idx, reward, done))\n",
    "        step += 1\n",
    "\n",
    "    schedule = env.last_schedule\n",
    "    makespan = env.last_makespan\n",
    "    return trajectory, schedule, makespan\n",
    "\n",
    "traj, schedule, makespan = run_eval_episode(env, policy_eval)\n",
    "len(traj), makespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Gantt-like plot of the resulting schedule\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "machine_ids = sorted(schedule.keys())\n",
    "yticks = []\n",
    "yticklabels = []\n",
    "\n",
    "for i, m_id in enumerate(machine_ids):\n",
    "    ops = schedule[m_id]\n",
    "    yticks.append(i)\n",
    "    y = i\n",
    "    yticklabels.append(f\"M{m_id}\")\n",
    "    for (job_id, op_idx, start, end) in ops:\n",
    "        ax.barh(y, end - start, left=start, edgecolor=\"black\")\n",
    "        ax.text(start + 0.1, y, f\"J{job_id}-O{op_idx}\", va=\"center\", ha=\"left\", fontsize=8)\n",
    "\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(yticklabels)\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_title(f\"Schedule Gantt chart (makespan={makespan:.2f})\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

